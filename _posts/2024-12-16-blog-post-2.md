---
title: 'Adding Conditional Control to Text-to-Image Diffusion Models'
date: 2024-12-16
permalink: /posts/2024/12/blog-post-2/
tags:
  - Blog
  - Paper Reading
---
## [See full version of this blog on Notion](https://field-board-61c.notion.site/Adding-Conditional-Control-to-Text-to-Image-Diffusion-Models-15e24e9716e480f0adfff17608340587?pvs=4)
# Introduction

- Motivation  
text-to-image models are limited in the control in spatial composition of the image; and it is difficult for text prompt to express complex layouts, poses, shapes and forms.  
want to develop a finer grained spatial control by letting users provide additional images that directly specify their desired image composition.  


- Challenge  
training data for specific condition may be significantly smaller than general dataset.  
may cause overfitting or forgetting.  
designing deeper or more customized neural architectures might be necessary for handling in-the-wild conditioning images with complex shapes and diverse high-level semantics.  
